{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE3b83Z-nOMr"
   },
   "source": [
    "\n",
    "##**ChipNet**\n",
    "\n",
    "This notebook demonstrates the implementation of the paper - **ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations**\n",
    "\n",
    "Steps to train a baseline model and then compress it for a given budget are as follows: \n",
    "*   Load the YAML file.\n",
    "*   Load dataset and create dataloaders.\n",
    "*   Create ChipNet object and pass the parameters in the form of a dictionary.\n",
    "*   Pass the dataloaders into the compress_model method to obtain the compressed model.\n",
    "\n",
    "Since this is a demo notebook the number of epochs have been set to 1, 1 and 2 respectively for pretraining, pruning and finetuning respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/hachons/trailmet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/trailmet/trailmet\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/trailmet/trailmet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 0d4d37c..e1e6e48\n",
      "error: Your local changes to the following files would be overwritten by merge:\n",
      "\ttrailmet/algorithms/algorithms.py\n",
      "Please commit your changes or stash them before you merge.\n",
      "error: The following untracked working tree files would be overwritten by merge:\n",
      "\texperiments/pruning/chip/chip.yaml\n",
      "\ttrailmet/algorithms/prune/chip.py\n",
      "Please move or remove them before you merge.\n",
      "Aborting\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sawZx2AaUrSb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from trailmet.models import ModelsFactory\n",
    "from trailmet.datasets.classification import DatasetFactory\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "f1F3p74GUurK"
   },
   "outputs": [],
   "source": [
    "root = \"/workspace/trailmet/trailmet/experiments/pruning/chipnet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kumEj_KQoDa6"
   },
   "source": [
    "###Loading the yaml file for the configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gScM1VukUyUd",
    "outputId": "532c5ad8-838e-499f-869a-10bb5a55b207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CHIPNET_ARGS': {'BUDGET_TYPE': 'channel_ratio', 'TARGET_BUDGET': 0.5, 'BUDGET_LOSS_WEIGHTAGE': 30, 'CRISPNESS_LOSS_WEIGHTAGE': 10, 'BETA_INCREMENT': 5, 'GAMMA_INCREMENT': 2, 'STEEPNESS': 100}, 'PRETRAIN': {'EPOCHS': 1, 'TEST_ONLY': False, 'OPTIMIZER': 'SGD', 'LR': 0.05, 'SCHEDULER_TYPE': 1, 'WEIGHT_DECAY': 0.001}, 'HARD_PRUNE': {'EPOCHS': 1, 'TEST_ONLY': False, 'OPTIMIZER': 'SGD', 'LR': 0.001, 'WEIGHT_DECAY': 0.001}, 'FINETUNE': {'EPOCHS': 1, 'TEST_ONLY': False, 'OPTIMIZER': 'SGD', 'LR': 0.05, 'SCHEDULER_TYPE': 1, 'WEIGHT_DECAY': 0.001}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "with open(os.path.join(root, \"chipnet.yaml\"), 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "print(data_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IA1AN-IzoK5q"
   },
   "source": [
    "###Loading the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nB_iWiaeWUuZ"
   },
   "outputs": [],
   "source": [
    "model = ModelsFactory.create_model('resnet50', 100, False, insize=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hb8NqjjFoNUh"
   },
   "source": [
    "###Loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GgpDcVBVU0nM"
   },
   "outputs": [],
   "source": [
    "from trailmet.datasets.classification import DatasetFactory\n",
    "data_root = \"/content/data_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPPq7RnSVo8C",
    "outputId": "a161435b-2d15-4aa0-f597-287468a6a8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/content/data_dir’: File exists\n"
     ]
    }
   ],
   "source": [
    "mkdir /content/data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osLzBsQeVwxw",
    "outputId": "4d32f266-58c2-41da-e698-b3eb91a2db1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose(\n",
    "[transforms.Resize(256),transforms.ToTensor()])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "[transforms.Resize(256),transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "[transforms.Resize(256),transforms.ToTensor()])\n",
    "\n",
    "transforms1 = {\n",
    "    'train': train_transform, \n",
    "    'val': val_transform, \n",
    "    'test': test_transform}\n",
    "def train_target_transform(label):\n",
    "    return label\n",
    "\n",
    "def val_target_transform(label):\n",
    "    return label\n",
    "\n",
    "def test_target_transform(label):\n",
    "    return label\n",
    "\n",
    "target_transforms = {\n",
    "    'train': None, \n",
    "    'val': None, \n",
    "    'test': None}\n",
    "\n",
    "\n",
    "chest_dataset = DatasetFactory.create_dataset(name = 'CIFAR100', \n",
    "                                        root = data_root,\n",
    "                                        split_types = ['train', 'val', 'test'],\n",
    "                                        val_fraction = 0.2,\n",
    "                                        transform = transforms1,\n",
    "                                        target_transform = target_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYUC-GRxoTs4"
   },
   "source": [
    "###Creating the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LvP7d7IYV1q_"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        chest_dataset['train'], batch_size=64, \n",
    "        sampler=chest_dataset['train_sampler'],\n",
    "        num_workers=0\n",
    "    )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        chest_dataset['val'], batch_size=64, \n",
    "        sampler=chest_dataset['val_sampler'],\n",
    "        num_workers=0\n",
    "    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        chest_dataset['test'], batch_size=64, \n",
    "        sampler=chest_dataset['test_sampler'],\n",
    "        num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxxv1kvnoZUL"
   },
   "source": [
    "###Creating the method's object followed by compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7LK8Pw3lWKVA"
   },
   "outputs": [],
   "source": [
    "from trailmet.algorithms.prune.chipnet import ChipNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gRxxsYSZWMpQ"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mChipNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_loaded\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/trailmet/trailmet/trailmet/algorithms/prune/chipnet.py:128\u001b[0m, in \u001b[0;36mChipNet.__init__\u001b[0;34m(self, model, dataloaders, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_inc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCHIPNET_ARGS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBETA_INCREMENT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5.\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_inc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCHIPNET_ARGS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGAMMA_INCREMENT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2.\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_budget \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_budget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteepness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mceLoss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized"
     ]
    }
   ],
   "source": [
    "a = ChipNet(model, {'train': train_loader, 'val': val_loader, 'test': test_loader}, **data_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpsqRsKgWPtj",
    "outputId": "30b2b27a-007f-4aad-f685-8eb572b4a4c3"
   },
   "outputs": [],
   "source": [
    "a.compress_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNNYHtfi466iTgScQQ0I9MP",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
